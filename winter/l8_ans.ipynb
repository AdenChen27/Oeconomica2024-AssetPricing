{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b50191",
   "metadata": {},
   "source": [
    "\n",
    "# Regression Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e8a76f",
   "metadata": {},
   "source": [
    "\n",
    "# Shape\n",
    "Given a `numpy` array `A`, what does `A.reshape((a, b))` do?\n",
    "\n",
    "What does `A.reshape((-1, 1))` do? In what way is `A.reshape((-1, 1))` different from `A`?\n",
    "\n",
    "Hint: one is a matrix, the other a vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1, 5, 10, 14, 31, 22, 27, 72])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16f9f8",
   "metadata": {},
   "source": [
    "\n",
    "# `Smoke`\n",
    "\n",
    "Explore the `smoke` data set from Wooldridge.\n",
    "Read [this](http://fmwww.bc.edu/ec-p/data/wooldridge/smoke.des).\n",
    "Produce a scatter plot of smoking behavior and income.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"smoke.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501823a7",
   "metadata": {},
   "source": [
    "\n",
    "# Simple Regression Analysis\n",
    "\n",
    "The following code runs a simple regression for `cigs` on `lincome`.\n",
    "(What does `\"\\t\"` mean?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fec4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "x = df[\"lincome\"].to_numpy().reshape((-1, 1))\n",
    "y = df[\"cigs\"].to_numpy()\n",
    "model.fit(x, y)\n",
    "\n",
    "r_sq = model.score(x, y)\n",
    "\n",
    "print(f\"beta_0:\\t{model.intercept_}\")\n",
    "print(f\"beta_1:\\t{model.coef_}\")\n",
    "print(f\"R^2:\\t{r_sq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1a5c00",
   "metadata": {},
   "source": [
    "\n",
    "You've obtained $\\beta_0$ and $\\beta_1$ above.\n",
    "Calculate the predicted value $\\hat{y}_i = \\beta_0 + \\beta_1 x_i$ for each of the entry in `df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864e3855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5d3e64d",
   "metadata": {},
   "source": [
    "\n",
    "Plot the following in the same graph:\n",
    "\n",
    "- The actual values of smoking vs income. (You have plotted this before. Just reproduce the graph).\n",
    "- The predicted values of smoking vs income for each entry in `df`.\n",
    "- The population regression function $E(y | x) = \\beta_0 + \\beta_1 x$. This should be a straight line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4265e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e4b7bd4",
   "metadata": {},
   "source": [
    "\n",
    "## Covariance\n",
    "\n",
    "The residual $\\hat{u}$ is the variation in $y_i$ not captured in our model, given by $\\hat{u}_i = y_i - \\hat{y}_i$.\n",
    "\n",
    "- Use to function to calculate, for each entry in `df`, the corresponding residual.\n",
    "- Calculate the sample covariance between the predicted value $\\hat{y}_i = \\beta_0 + \\beta_1 x_i$ and the error $\\hat{u}_i = y_i - \\hat{y}_i$. Note its magnitude.\n",
    "\n",
    "Hint: use [`np.cov`](https://numpy.org/doc/stable/reference/generated/numpy.cov.html). (This function returns a matrix. How does the matrix relate to the covariance?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52edfecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5131d525",
   "metadata": {},
   "source": [
    "\n",
    "You should obtain 0 (up to any small rounding error). In fact, we always have for *any* sample that $Cov(\\hat{y}_i, \\hat{u}_i) = 0$.\n",
    "The fitted values and the residuals are uncorrelated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0169c",
   "metadata": {},
   "source": [
    "\n",
    "## Correlation\n",
    "\n",
    "Using $\\beta_0$ and $\\beta_1$, you can obtain estimated values of `cigs`, `predicted_cigs` as:\n",
    "$$\n",
    "    \\text{predicted_cigs} = \\beta_0 + \\beta_1 \\text{lincome}.\n",
    "$$\n",
    "\n",
    "- Create thus a new column called `predicted_cigs` in the DataFrame with the predicted values of cigs using the values of $\\beta_0$ and $\\beta_1$ you obtained.\n",
    "- Calculate the *square* of the correlation coefficient between `predicted_cigs` and `cigs`. Compare the value you get with the parameters of the model. What do you find?\n",
    "\n",
    "Hint: use [`np.corrcoef`](https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html). (This function returns a matrix. How does the matrix relate to the covariance?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"predicted_cigs\"] = model.intercept_ + model.coef_[0]*df[\"lincome\"]\n",
    "np.corrcoef(df[\"predicted_cigs\"], df[\"cigs\"])**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b227b8",
   "metadata": {},
   "source": [
    "\n",
    "# Multiple Regression Analysis\n",
    "\n",
    "The [`statsmodels`](https://www.statsmodels.org/stable/index.html) module provides a much more convenient way to run regressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "result = sm.ols(formula=\"cigs ~ lincome\", data=df).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdcd7d",
   "metadata": {},
   "source": [
    "\n",
    "The above one line code, for example, runs the simple regression of `cigs` on `lincome` which you've done above. (You are asked to use `sklearn.linear_model import LinearRegression` previously to make sure you actually understand what coefficient and intercept means.)\n",
    "\n",
    "You can just as easily run multiple regressions, that is, regression on multiple explanatory variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985b99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.ols(formula=\"cigs ~ lincome + age + cigpric + educ\", data=df).fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d05b9b",
   "metadata": {},
   "source": [
    "\n",
    "# Life Satisfaction\n",
    "\n",
    "Explore World Happiness Report's [`datasets/WorldHappinessReport2024_DataForTable2.1.csv`](https://worldhappiness.report/data/) dataset on world happiness in 2024 (measured using the [Cantril ladder](https://news.gallup.com/poll/122453/understanding-gallup-uses-cantril-scale.aspx)).\n",
    "\n",
    "- Rename the columns (having spaces in names can be extremely annoying, as you might or might not experience if you ignore this step).\n",
    "    \n",
    "    You may want to use the following dictionary for renaming.\n",
    "    ```\n",
    "    {\n",
    "        \"Country name\": \"country\",\n",
    "        \"Life Ladder\": \"ladder\",\n",
    "        \"Log GDP per capita\": \"logGDP\",\n",
    "        \"Social support\": \"socialSupport\",\n",
    "        \"Healthy life expectancy at birth\": \"health\",\n",
    "        \"Freedom to make life choices\": \"freedom\",\n",
    "        \"Generosity\": \"generosity\",\n",
    "        \"Perceptions of corruption\": \"corruption\",\n",
    "        \"Positive affect\": \"positiveAffect\",\n",
    "        \"Negative affect\": \"negativeAffect\",\n",
    "    }\n",
    "    ```\n",
    "- Let's focus for simplicity on cross-sectional data. To that end, isolate the relevant data in year 2023.\n",
    "\n",
    "- Regress happiness (`ladder`) on two explanatory variables `logGDP` and `freedom`.\n",
    "\n",
    "The regression model is:\n",
    "$$\n",
    "    \\text{ladder} = \\beta_0 + \\beta_1 \\text{logGDP} + \\beta_2 \\text{health} + u.\n",
    "$$\n",
    "What value of $\\beta_1$ did you get?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36291f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/WorldHappinessReport2024_DataForTable2.1.csv\")\n",
    "df = df.rename(columns={\n",
    "    \"Country name\": \"country\",\n",
    "    \"Life Ladder\": \"ladder\",\n",
    "    \"Log GDP per capita\": \"logGDP\",\n",
    "    \"Social support\": \"socialSupport\",\n",
    "    \"Healthy life expectancy at birth\": \"health\",\n",
    "    \"Freedom to make life choices\": \"freedom\",\n",
    "    \"Generosity\": \"generosity\",\n",
    "    \"Perceptions of corruption\": \"corruption\",\n",
    "    \"Positive affect\": \"positiveAffect\",\n",
    "    \"Negative affect\": \"negativeAffect\",\n",
    "})\n",
    "result = sm.ols(formula=\"ladder ~ logGDP + freedom\", data=df).fit()\n",
    "beta_1 = result.params[\"logGDP\"]\n",
    "print(beta_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5843c",
   "metadata": {},
   "source": [
    "\n",
    "Next, regress `logGDP` on `freedom`. The regression model is:\n",
    "$$\n",
    "    \\text{logGDP} = \\gamma_0 + \\gamma_1 \\text{freedom} + u_2.\n",
    "$$\n",
    "- What values of $\\gamma_0$ and $\\gamma_1$ did you get?\n",
    "\n",
    "Using $\\gamma_0$ and $\\gamma_1$, you can obtain estimated values of `logGDP`, `predicted_logGDP` as:\n",
    "$$\n",
    "    \\text{predicted_logGDP} = \\gamma_0 + \\gamma_1 \\text{freedom}.\n",
    "$$\n",
    "\n",
    "- Create thus a new column called `predicted_logGDP` in the DataFrame with the predicted values of logGDP using the values of $\\gamma_0$ and $\\gamma_1$ you obtained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03828dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.ols(formula=\"logGDP ~ freedom\", data=df).fit()\n",
    "gamma_0 = result.params[\"Intercept\"]\n",
    "gamma_1 = result.params[\"freedom\"]\n",
    "\n",
    "df[\"predicted_logGDP\"] = gamma_1*df[\"freedom\"] + gamma_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae1b18",
   "metadata": {},
   "source": [
    "\n",
    "The difference between the predicted value and the true value is called the residual.\n",
    "$$\n",
    "    \\text{residual} = \\text{logGDP} - \\text{predicted_logGDP}\n",
    "$$\n",
    "- Create a new column called `residual` containing the residuals.\n",
    "- Run a regression of `ladder` on `residual`.\n",
    "\n",
    "The regression model is:\n",
    "$$\n",
    "    \\text{ladder} = \\beta_0' + \\beta_1' \\text{residual} + u_3.\n",
    "$$\n",
    "What value of $\\beta_1'$ did you get? How does it compare to $\\beta_1$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"residual\"] = df[\"logGDP\"] - df[\"predicted_logGDP\"]\n",
    "result = sm.ols(formula=\"ladder ~ residual\", data=df).fit()\n",
    "print(result.params[\"residual\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e49d073",
   "metadata": {},
   "source": [
    "\n",
    "This result is known as the Frisch-Waugh-Lovell theorem or the regression anatomy formula.\n",
    "\n",
    "We thus have a new interpretation of $\\beta_1$: \n",
    "$\\text{residual}$ is `logGDP` after the effect of `freedom` has been partialled out, and $\\beta_1 = \\beta_1'$ effect of `logGDP` on `ladder` after the effect of `freedom` has been partialled out.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
