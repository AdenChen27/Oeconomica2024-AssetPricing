\documentclass[oneside,reqno,letterpaper]{amsart}

\usepackage{silence} % for suppressing warnings
\WarningFilter{mdframed}{You have requested package}

\usepackage[plain]{/Users/aden/Library/CloudStorage/Box-Box/latex/adenc}




\title[AP-Lec01]{Asset Pricing: Mathematical Foundations}
\author{Aden Chen}



\begin{document}
\maketitle

\tableofcontents

\section{Derivatives: A One-Dimensional Recap}


\blfootnote{Date: \today}
\blfootnote{The most recent version of this document can be found \href{https://github.com/AdenChen27/Oeconomica2024-AssetPricing/blob/main/autumn/math-foundations.pdf}{here}.}


\begin{definition}
  Let \(f: \RR \supset \Omega \to \RR\). 
  The derivative of \(f\) at \(x \in \Omega\) is defined as 
  \[
    f'(x) = \lim_{h \to 0} \frac{f(x + h) - f(x)}{h} , 
  \] 
  if the limit exists. 
\end{definition}
\begin{remark}~
  \begin{itemize}
    \item Think ``first order approximation.''
    \item Note that \(f'\) is also a function, with the same domain as \(f\) (when \(f\) is enough regular). 
  \end{itemize}
\end{remark}



\section{Derivatives: Partial and Total}
\begin{definition}
  Let \(f: \RR^n \supset \Omega \to \RR\). 
  The partial derivative of \(f\) at \(\vec{x} \in \Omega\) with respect to the \(i\)th variable is defined as 
  \[
    \frac{\partial f}{\partial x_i}
    = f_{x_i}
    = f_i(x) 
    = \lim_{h \to 0} \frac{f(\vec{x} + h \vec{e}_i) - f(\vec{x})}{h} , 
  \] 
  if the limit exists. 
\end{definition}
\begin{remark}~
  \begin{itemize}
    \item \href{https://www.desmos.com/3d/qvhgjqbkax}{Desmos 3d Demo}. 
    \item Think derivative with respect to the \(i\)th position, not to \(x_i\). 
    \item ``First order approximation in the \(i\)th direction.``
    \item With enough regularity imposed on \(f\), we can write 
      \[
        \d f = \sum_{k = 1}^{n} \frac{\partial f}{\partial x_i} . 
      \] 
      ``Think first order approximation.''
  \end{itemize}
\end{remark}



\section{The Lagrangian}
\begin{example}
  \[
    \max_{\{x, y\}} U(x, y), \quad \text{s.t.} 
    \begin{cases}
      p_x x + p_y y \leq m \\ 
      x, y \geq 0
    \end{cases}
  \]
  \begin{itemize}
    \item For ease of mathematics, we often consider the constraint \(p_x x + p_y y = m\). 
    \item For a more general case, see \href{https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions}{Karush–Kuhn–Tucker conditions}. 
  \end{itemize}
\end{example}


\begin{theorem}
  More abstractly, the above problem can be thought of as 
  \[
    \max f(x_1, x_2) \quad \text{ s.t. } g(x_1, x_2) = c 
  \] 
  for a constant \(c\). 
  With enough regularity, the optima occurs at the critical points of the Lagrangian, defined as 
  \[
    \cL(x_1, x_2, \lambda)
    \coloneqq f(x_1, x_2) + \lambda [c - g(x_1, x_2)] . 
  \] 
  That is, the optima subject to given constraint satisfies 
  \begin{align*}
    [x_1]: && f_1(x_1^*, x_2^*) &= \lambda g_1(x_1^*, x_2^*) \\ 
    [x_2]: && f_2(x_1^*, x_2^*) &= \lambda g_2(x_1^*, x_2^*) \\ 
    [\lambda]: && g(x_1^*, x_2^*) &= c . 
  \end{align*}
\end{theorem}

\section{Lagrangian: An Example}
\subsection{The Utility Maximization Problem}
The problem:
\[
  v(p_x, p_y, m) \coloneqq
  \max_{x, y} U(x, y) \quad \text{s.t.} \quad p_x x + p_y y = m . 
\] 

\subsection{Interpretation}
We want to maximize 
\[
  \d U = U_x \d x + U_y \d y 
\] 
such that 
\[
  p_x \d x + p_y \d y = 0 \implies 
  \d y = - \frac{p_x}{p_y} \d x . 
\] 
This gives 
\[
  \d U = \left[ U_x - U_y \cdot \frac{p_x}{p_y} \right] \d x . 
\] 
% This tells ``what we should do.''
% If \(\left[ \cdot \right] > 0\), then set \(\d x > 0\) (buy more \(x\)), etc. 
We can rewrite these two expressions in the following forms:
\begin{itemize}
  \item Set \(\d x > 0\) if \(U_x / U_y > p_x / p_y\). 
    \[
      \left[ \frac{U_x}{U_y} - \frac{p_x}{p_y} \right] U_y \dd x
    \] 
    ``Take advantage of all trading opportunities.''

  \item Set \(\d x > 0\) if \(U_x / p_x > U_y / p_y\). 
    Note that \(U_x / p_y\) is marginal utility of money \emph{spent on \(x\)}. 
    \[
      \left[ \frac{U_x}{p_x} - \frac{U_y}{p_y} \right] p_x \dd x
    \] 
    ``Bang for your buck.''
    
  \item Set \(\d x > 0\) if \(U_x > U_y \cdot p_x / p_y\). 
    Note that \(U_x\) is the marginal benefit of buying \(x\) and \(U_y \cdot p_x / p_y\) is the marginal cost of buying \(x\). 
    \[
      \left[ U_x - U_y \cdot \frac{p_x}{p_y} \right] \d x
    \] 
    ``Trade until marginal cost equals marginal benefit.''
\end{itemize}
In the last expression, if we write 
\[
  \lambda = \frac{U_y}{p_y}, 
\] 
(think marginal utility of income) we have that at optimum, 
\begin{gather*}
  (U_x - \lambda p_x) \d x = 0 , \\ 
  \lambda = \frac{U_y}{p_y} \iff U_y - \lambda p_y = 0 , \\ 
  p_x x + p_y y = m . 
\end{gather*}
These three equalities describe precisely the critical points of the following 
\[
  \cL(p_x, p_y, \lambda) \coloneqq
  U(x, y) + \lambda \left[ m - p_x x - p_y y \right], 
\] 
called the \vocab{Lagrangian}. 
That is, setting 
\[
  \frac{\partial \cL}{\partial x} = \frac{\partial \cL}{\partial y} = \frac{\partial \cL}{\partial \lambda} = 0
\] 
recovers the above three equations. 

\begin{remark}~
  \begin{itemize}
    \item We are not maximizing the Lagrangian but utility level (subject to given constraint).
    \item \(\lambda\) might be negative or zero. 
      Think bliss point. 
  \end{itemize}
\end{remark}


\section{Taylor Expansion}
\begin{definition}
  The Taylor polynomial of degree \(n\) of the function \(f\) around point \(a\) is given by 
  \[
    P(a + x) = \sum_{k = 1}^{n} \frac{f^{(n)}(a)}{k!} \cdot x^{k} . 
  \] 
  It has the same \(k\) derivatives as \(f\). 
  Think ``\(k\)th order approximation.``
\end{definition}
\begin{remark}
  We will often use the first or second order approximation starting from a given point \(a\):
  \begin{align*}
    f(a + h) &\approx f(a) + f'(a) h, \\
    f(a + h) &\approx f(a) + f'(a) h + f''(a) h^2. 
  \end{align*}
\end{remark}



\section{Probability}
\begin{definition}
  A discrete random variable \(X\) can be described by the (at most countable) values it can attain and the probability of attaining them.

  % Let \(S\) be the set of all attainable values.
  \begin{itemize}
  \item 
    The expectation of \(X\) is defined as 
    \[
      \E(X) = \sum x \cdot \P(X = x) . 
    \] 
    Think weighted average. 

  \item 
    The variance of \(X\) is defined as 
    \[
      \Var(X) = \E[(X - \E(X))^2] . 
    \] 

  \item For discrete random variables \(X\) and \(Y\), the covariance is defined by
    \[
      \Cov(X, Y) = \E[(X - \E(X)) \cdot (Y - \E(Y))] .
    \] 
  \end{itemize}
\end{definition}

\begin{proposition}~
  \begin{itemize}
    \item \(\E\) is linear. 
      That is, \(\E[a + bX] = a + b \E[X]\) for \(a, b \in \RR\). 
    \item \(\Var(X) = \E(X^2) - \E(X)^2\) and 
      \(\Var(a + bX) = b^2 \Var(X)\). 
    \item \(\Cov(X, Y) = \E(XY) - \E(X) \E(Y)\). 
  \end{itemize}
\end{proposition}


















\end{document}


